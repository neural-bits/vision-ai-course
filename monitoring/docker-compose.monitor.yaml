version: '3.4'

services:
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    container_name: prometheus
    restart: always
    volumes:
      - "./datasources:/etc/prometheus/provisioning/datasources"
      - /var/run/docker.sock:/var/run/docker.sock:ro
    command:
      - "--config.file=/etc/prometheus/provisioning/datasources/scraping.yaml"
      - "--enable-feature=expand-external-labels"
    networks:
      - monitoring-network

  grafana:
    image: grafana/grafana-enterprise:8.2.0
    container_name: grafana
    ports:
      - "3000:3000"
    volumes:
      - "./datasources:/etc/grafana/provisioning/datasources"
      - "./dashboards:/etc/grafana/provisioning/dashboards"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PWD}
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER}
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
    networks:
      - monitoring-network


  # cadvisor:
  #   image: gcr.io/cadvisor/cadvisor:latest
  #   container_name: cadvisor
  #   restart: always
  #   ports:
  #     - "8080:8080"
  #   volumes:
  #     - "/etc/localtime:/etc/localtime:ro"
  #     - "/etc/timezone:/etc/timezone:ro"
  #     - "/:/rootfs:ro"
  #     - "/var/run:/var/run:rw"
  #     - "/sys:/sys:ro"
  #     - "/var/lib/docker:/var/lib/docker:ro"
  #   networks:
  #     - monitoring-network

  triton_server:
    container_name: triton-inference-server-23.10
    image: nvcr.io/nvidia/tritonserver:23.10-py3  
    privileged: true
    ports:
      - "8001:8001"
      - "8002:8002"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
    volumes:
      - ${PWD}/../model_repository:/models
    command: ["tritonserver", "--model-repository=/models"]

    networks:
      - monitoring-network

networks:
  monitoring-network:
    external: true
